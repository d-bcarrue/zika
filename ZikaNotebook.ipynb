{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción\n",
    "Predicción de síntomas en un paciente con una cepa específica del virus Zika usando datos clínicos específicos y métodos de Machine Learning.\n",
    "?? Sólo tenemos un output. Yo digo que es si muere o no.\n",
    "## Métodos\n",
    "Muchos\n",
    "**Procesado de datos**\n",
    "- Buscar errores o missing values y eliminar estas filas.\n",
    "    No había ninguno.\n",
    "- Cambiar escala de features.\n",
    "    Ya están estandarizadas.\n",
    "    \n",
    "- Feature Selection.\n",
    "    Probamos pero no lo hacemos por ser características médicas.\n",
    "    \n",
    "- Balanceo de clases.\n",
    "    Hacemos undersampling para balancear.\n",
    "- Separación en conjuntos de entrenamiento, validación y test.\n",
    "\n",
    "**Machine Learning**\n",
    "\n",
    "- Use any method of ML / Deep Learning you consider to obtain the best model for your task/problem.\n",
    "- Use metrics of ML to decide the best model.\n",
    "- Save the model if possible as file.\n",
    "\n",
    "## Resultados y discusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import (train_test_split, GridSearchCV,\n",
    "                                     ParameterGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos dataset\n",
    "df = pd.read_csv(os.path.join('ds_Zika.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos si falta algún valor\n",
    "attr = []\n",
    "# Iteramos los atributos del dataset\n",
    "for i in df.columns:\n",
    "    # Comprobamos los valores de cada atributo\n",
    "    attr.append(np.all(df[i].notna()))\n",
    "# Ningún atributo tiene missing values:\n",
    "np.all(np.array(attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18557084417999256"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanceo de clases\n",
    "# Comprobamos la proporción\n",
    "np.mean(df[\"Output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "# Número de casos positivos\n",
    "nposit = len(df[df['Output'] == 1])\n",
    "# Índices de casos negativos\n",
    "inegat = df[df.Output == 0].index\n",
    "# Cogemos aleatoriamente un número de índices negativos igual al número de casos positivos\n",
    "random_indices = np.random.choice(inegat, nposit, replace=False)\n",
    "# Obtenemos todos los índices positivos\n",
    "iposit = df[df.Output == 1].index\n",
    "# Unimos las dos listas de índices\n",
    "new_indices = np.concatenate([iposit, random_indices])\n",
    "df = df.loc[new_indices]\n",
    "# y las desordenamos\n",
    "df = shuffle(df).reset_index(drop=True)\n",
    "\n",
    "X = df.drop('Output', axis=1)\n",
    "y = df['Output']\n",
    "\n",
    "Xdata = X.values\n",
    "ydata = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación en conjuntos de entrenamiento y test:\n",
    "#ssplit = ShuffleSplit(n_splits=100, test_size=0.2)\n",
    "#for i_train, i_test in ssplit.split(Xdata):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprimimos warnings para legibilidad (nota: no recomendamos hacer esto)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K Neighbors\n",
    "# knb = KNeighborsClassifier()\n",
    "\n",
    "# # LDC:\n",
    "# ldc = LinearDiscriminantAnalysis()\n",
    "\n",
    "# # Bayesian:\n",
    "# gnb = GaussianNB()\n",
    "\n",
    "# # Multilayer Perceptron\n",
    "# mlp = MLPClassifier()\n",
    "\n",
    "# # SVM:\n",
    "# svm = SVC()\n",
    "\n",
    "# # Random Forest\n",
    "# rndf = RandomForestClassifier()\n",
    "\n",
    "# models = [knb, ldc, gnb, mlp, svm, rndf]\n",
    "# model_names = ['KNeighborsClassifier', 'LinearDiscriminantAnalysis', 'GaussianNB', 'MLPClassifier', 'SVC', 'RandomForestClassifier']\n",
    "# scores = []\n",
    "# for i,model in enumerate(models):\n",
    "#     score = cross_val_score(model, Xdata, ydata, cv=10)\n",
    "#     print(model_names[i], ' - Mean:', np.mean(score), ' - Standard Deviation:', np.std(score))\n",
    "# warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16, 'min_samples_leaf': 1, 'n_estimators': 91}\n",
      "validation accuracy: 0.9993319973279893\n",
      "test accuracy: 0.9398797595190381\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xdata, ydata,\n",
    "                                                    test_size=0.25,\n",
    "                                                    stratify=ydata)\n",
    "\n",
    "param_grid = {'n_estimators': range(1, 101, 10),\n",
    "               'max_depth': range(1, 26, 5),\n",
    "               'min_samples_leaf': range(1, 11, 5)}\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1234)\n",
    "grid = GridSearchCV(alg, param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "print('validation accuracy:', grid.score(X_train, y_train))\n",
    "print('test accuracy:', grid.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_train_score  mean_test_score  train_test_difference\n",
      "79          0.945075         0.925184               0.019892\n",
      "58          0.942552         0.924516               0.018036\n",
      "59          0.941810         0.923848               0.017963\n",
      "57          0.941513         0.922512               0.019001\n",
      "56          0.941958         0.922512               0.019447\n",
      "55          0.942033         0.922512               0.019521\n",
      "53          0.940919         0.921176               0.019743\n",
      "28          0.933793         0.917836               0.015958\n",
      "22          0.934980         0.915164               0.019817\n",
      "29          0.933942         0.915164               0.018778\n",
      "26          0.932680         0.915164               0.017516\n",
      "24          0.933867         0.914496               0.019372\n",
      "27          0.932828         0.914496               0.018333\n",
      "25          0.933125         0.914496               0.018630\n",
      "33          0.925036         0.912492               0.012544\n",
      "36          0.923476         0.912492               0.010985\n",
      "39          0.923922         0.911824               0.012098\n",
      "32          0.924368         0.911824               0.012544\n",
      "34          0.922586         0.911156               0.011430\n",
      "37          0.924070         0.911156               0.012914\n",
      "38          0.923773         0.911156               0.012617\n",
      "35          0.923476         0.911156               0.012321\n",
      "31          0.925704         0.908484               0.017220\n",
      "Max depth: 16 - Min. samples leaf: 6 - Num. estimators: 91\n"
     ]
    }
   ],
   "source": [
    "c = pd.DataFrame(grid.cv_results_)\n",
    "c['train_test_difference'] = c.mean_train_score - c.mean_test_score\n",
    "max_diff = 0.02\n",
    "min_test_score = 0.90\n",
    "c_sorted = c[(c.mean_test_score >= min_test_score) & (c.train_test_difference <= max_diff)][(\n",
    "    ['mean_train_score', 'mean_test_score','train_test_difference'])].sort_values('mean_test_score', ascending=False)\n",
    "print(c_sorted)\n",
    "i = c_sorted.first_valid_index()\n",
    "max_depth = c.param_max_depth.iloc[i]\n",
    "min_samples_leaf = c.param_min_samples_leaf.iloc[i]\n",
    "n_estimators = c.param_n_estimators.iloc[i]\n",
    "print('Max depth: {} - Min. samples leaf: {} - Num. estimators: {}'.format(max_depth, min_samples_leaf, n_estimators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.9953239812959251\n",
      "test accuracy: 0.9138276553106213\n"
     ]
    }
   ],
   "source": [
    "best = RandomForestClassifier(random_state=1234)\n",
    "best.fit(X_train, y_train)\n",
    "print('validation accuracy:', best.score(X_train, y_train))\n",
    "print('test accuracy:', best.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
